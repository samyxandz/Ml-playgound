{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrRsy+T3wpdy1Q8c8cyN4f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samyxandz/Ml-playgound/blob/main/AutoCorrect2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre processing step"
      ],
      "metadata": {
        "id": "VzbjieVfH0rE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtGZCojzHymB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(file_name):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        A file_name which is found in your current directory. You just have to read it in.\n",
        "    Output:\n",
        "        words: a list containing all the words in the corpus (text file you read) in lower case.\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    file = open(file_name, 'r')\n",
        "    text = file.read().lower()\n",
        "    file.close()\n",
        "    words = re.findall(r'\\w+', text)\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "NVmHpNaaIAU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### testing above function"
      ],
      "metadata": {
        "id": "UMczyEkRIScO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_l = process_data('shakespeare.txt')\n",
        "vocab = set(word_l)  # this will be your new vocabulary\n",
        "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0bgldiKIR8q",
        "outputId": "f21432ab-73cc-4302-d926-afd9e181aade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first ten words in the text are: \n",
            "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
            "There are 6116 unique words in the vocabulary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the word frequency table"
      ],
      "metadata": {
        "id": "wWLcdyQkJVuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(words):\n",
        "    '''\n",
        "    Input:\n",
        "        word_l: a set of words representing the corpus.\n",
        "    Output:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    '''\n",
        "    return dict(Counter(words))"
      ],
      "metadata": {
        "id": "zv52aG9EJSng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing the above function"
      ],
      "metadata": {
        "id": "WyWqo9YfJdh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = get_count(word_l)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
        "print(f\"The count for the word 'thee' is {word_count_dict.get('thee')}\")"
      ],
      "metadata": {
        "id": "8PxmtK_0JiC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d175b5f0-547c-44ac-b8e7-145e0cc8caa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 6116 key values pairs\n",
            "The count for the word 'thee' is 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model intuition\n",
        "\n",
        "\"Given the dictionary of word counts, compute the probability that each word will appear if randomly selected from the corpus of words.\n",
        "    \n",
        " $$P(w_i) = \\\\frac{C(w_i)}{M} \\$$\n",
        "\n",
        "where  $C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
        "    \n",
        "$M$ is the total number of words in the corpus.\n",
        "\n",
        "For example, the probability of the word 'am' in the sentence **'I am happy because I am learning'** is:\n",
        "\n",
        " $$P(am) = \\\\frac{C(w_i)}{M} \\$$\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QiPoKzreKic8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(word_frequencies):\n",
        "    '''\n",
        "    Input:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    Output:\n",
        "        probs: A dictionary where keys are the words and the values are the probability that a word will occur.\n",
        "    '''\n",
        "    probabilities = {}\n",
        "    total_words = len(word_l)\n",
        "\n",
        "    for word, frequency in word_frequencies.items():\n",
        "        probabilities[word] = frequency / total_words\n",
        "\n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "hrAzgZKiNe7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### testing above function"
      ],
      "metadata": {
        "id": "j7DhGJTWPcla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(f\"Length of probs is {len(probs)}\")\n",
        "print(f\"P('thee') is {probs['the']:.4f}\")"
      ],
      "metadata": {
        "id": "Boer4uS0OCL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec866cf-72b8-414f-f2cf-72a2a113674b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of probs is 6116\n",
            "P('thee') is 0.0284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# String Manipulations"
      ],
      "metadata": {
        "id": "kJPhkNPaPjrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will be making functions for following part\n",
        "\n",
        "- delete_letter: given a word, it returns all the possible strings that have one character removed.\n",
        "- switch_letter: given a word, it returns all the possible strings that have two adjacent letters switched.\n",
        "- replace_letter: given a word, it returns all the possible strings that have one character replaced by another different letter.\n",
        "- insert_letter: given a word, it returns all the possible strings that have an additional character inserted."
      ],
      "metadata": {
        "id": "kkprSaJdWQJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### delete_letter( )\n",
        " given a word, returns a list of strings with one character deleted.\n",
        "\n",
        "For example, given the word nice, it would return the set:\n",
        "\n",
        "{'ice', 'nce', 'nic', 'nie'}."
      ],
      "metadata": {
        "id": "Mp6MIL0OXZgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the string/word for which you will generate all possible words\n",
        "                in the vocabulary which have 1 missing character\n",
        "    Output:\n",
        "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
        "    '''\n",
        "\n",
        "    delete_l = [word[:i] + word[i + 1:] for i in range(len(word))]\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "\n",
        "    if verbose: print(f\"input word {word} \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return delete_l"
      ],
      "metadata": {
        "id": "duPpNxdKPojW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_word_l = delete_letter(word=\"cans\",verbose=True)"
      ],
      "metadata": {
        "id": "5h7D85JvYrYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c4e6e1-5559-40d7-a720-1b1b05c5fed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word cans \n",
            "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
            "delete_l = ['ans', 'cns', 'cas', 'can']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### switch_letter( )\n",
        "\n",
        "  a function that switches two letters in a word. It takes in a word and returns a list of all the possible switches of two letters that are adjacent to each other.\n",
        "\n",
        "For example, given the word 'eta', it returns\n",
        "{'eat', 'tea'}, but does not return 'ate'.\n",
        "\n"
      ],
      "metadata": {
        "id": "3acyf0h1Z0sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: input string\n",
        "     Output:\n",
        "        switches: a list of all possible strings with one adjacent charater switched\n",
        "    '''\n",
        "\n",
        "    switch_l = [word[:i] + word[i + 1] + word[i] + word[i + 2:] for i in range(len(word) - 1)]\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "\n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\")\n",
        "\n",
        "    return switch_l"
      ],
      "metadata": {
        "id": "Zw1-Tt0zahfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### testing above function"
      ],
      "metadata": {
        "id": "WalDpQz0a7GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "switch_word_l = switch_letter(word=\"eta\", verbose=True)"
      ],
      "metadata": {
        "id": "wn8zBn41a_QY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcdef8e-8737-48a2-bf3b-d5d47d418109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = eta \n",
            "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
            "switch_l = ['tea', 'eat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### replace_letter( )\n",
        "\n",
        "  takes in a word and returns a list of strings with one replaced letter from the original word.\n",
        "\n",
        "\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        replaces: a list of all possible strings where we replaced one letter from the original word.\n",
        "\n"
      ],
      "metadata": {
        "id": "GJGAvfHQbjAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letter(word, verbose=False):\n",
        "\n",
        "\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_l = []\n",
        "    for i in range(len(word)):\n",
        "        for letter in letters:\n",
        "            if letter != word[i]:\n",
        "                replace_l.append(word[:i] + letter + word[i + 1:])\n",
        "    replace_l.sort()\n",
        "\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "\n",
        "    if verbose: print(f\"Input word = {word} \\n split_l = {split_l} \\nreplace_l= \\n {replace_l}\")\n",
        "\n",
        "    return replace_l"
      ],
      "metadata": {
        "id": "Dt2hFpF2cTj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing above function"
      ],
      "metadata": {
        "id": "xbf6CfLFc0q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replace_l = replace_letter(word='can', verbose=True)"
      ],
      "metadata": {
        "id": "V0E7YqaOc6ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4989850-0912-4ea4-ec63-e7620c50f34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = can \n",
            " split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
            "replace_l= \n",
            " ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### insert_letter( )\n",
        "\n",
        "  a function that takes in a word and returns a list with a letter inserted at every offset.\n",
        "\n",
        "\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "  \n"
      ],
      "metadata": {
        "id": "157YSqDNdC-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    insert_l = [a + letter + b for a, b in split_l for letter in letters]\n",
        "\n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "\n",
        "    return insert_l"
      ],
      "metadata": {
        "id": "b0aEJ087dfN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing above function"
      ],
      "metadata": {
        "id": "IApjhuk2dqkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insert_l = insert_letter('at', True)\n",
        "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
      ],
      "metadata": {
        "id": "kgcjl93AdpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bed48dc-dde3-41eb-fdbf-925b08475069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word at \n",
            "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
            "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
            "Number of strings output by insert_letter('at') is 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining the edits"
      ],
      "metadata": {
        "id": "rNA9wIZleCAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating  two functions that, given a string, will return all the possible single and double edits on that string.\n",
        "These will be `edit_one_letter() ` and ` edit_two_letters() `."
      ],
      "metadata": {
        "id": "jwxZZPaHeMo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit at One letter"
      ],
      "metadata": {
        "id": "JMiUO4IlfU3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function to get all the possible edits that are one edit away from a word. The edits consist of the replace, insert, delete, and optionally the switch operation. You should use the previous functions you have already implemented to complete this function. The 'switch' function is a less common edit function, so its use will be selected by an \"allow_switches\" input argument.\n",
        "\n",
        "\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "vb6XiLt4feTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "\n",
        "\n",
        "    edit_one_set = set().union(replace_letter(word)).union(insert_letter(word)).union(delete_letter(word))\n",
        "\n",
        "    if allow_switches:\n",
        "        edit_one_set = edit_one_set.union(switch_letter(word))\n",
        "\n",
        "    return edit_one_set"
      ],
      "metadata": {
        "id": "U7_gjpVwfyLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the function\n"
      ],
      "metadata": {
        "id": "gELDvVYXfuyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "# turn this into a list to sort it, in order to view it\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
        "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
      ],
      "metadata": {
        "id": "2XESdBBNgEOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59c0712-959c-4291-fa9e-13fa42cf283d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n",
            "Number of outputs from edit_one_letter('at') is 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit at Two letter"
      ],
      "metadata": {
        "id": "TQ9UPnEXgk-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generalize this to implement to get two edits on a word.\n",
        "\n",
        "we have to get all the possible edits on a single word and then for each modified word, you would have to modify it again.\n",
        "\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        edit_two_set: a set of strings with all possible two edits"
      ],
      "metadata": {
        "id": "HvMybktggsv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "\n",
        "    edit_one_set = edit_one_letter(word, allow_switches)\n",
        "    edit_two_set = set()\n",
        "\n",
        "    for entry in edit_one_set:\n",
        "        edit_two_set = edit_two_set.union(edit_one_letter(entry, allow_switches))\n",
        "\n",
        "    return edit_two_set"
      ],
      "metadata": {
        "id": "hca200_2g7j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the function\n"
      ],
      "metadata": {
        "id": "1gIvmyTbhZwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "\n",
        "print(f\"Number of strings that are 2 edit distances from 'a' is {len(edit_two_letters('a'))}\")"
      ],
      "metadata": {
        "id": "5cWFawzQhdIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81cbb85-cd03-453b-b632-3a012095c77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
            "Number of strings that are 2 edit distances from 'a' is 2654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WARNING\n",
        "\n",
        "will show all the elements at edit distance 2\n"
      ],
      "metadata": {
        "id": "aYVQjRA5iGj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "\n",
        "print(f\" The strings are :{tmp_edit_two_l}\")"
      ],
      "metadata": {
        "id": "QADGAoq6iHDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e07da9-2cb8-4ba6-b51e-7a078cc2de87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The strings are :['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag', 'aah', 'aai', 'aaj', 'aak', 'aal', 'aam', 'aan', 'aao', 'aap', 'aaq', 'aar', 'aas', 'aat', 'aau', 'aav', 'aaw', 'aax', 'aay', 'aaz', 'ab', 'aba', 'abb', 'abc', 'abd', 'abe', 'abf', 'abg', 'abh', 'abi', 'abj', 'abk', 'abl', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz', 'ac', 'aca', 'acb', 'acc', 'acd', 'ace', 'acf', 'acg', 'ach', 'aci', 'acj', 'ack', 'acl', 'acm', 'acn', 'aco', 'acp', 'acq', 'acr', 'acs', 'act', 'acu', 'acv', 'acw', 'acx', 'acy', 'acz', 'ad', 'ada', 'adb', 'adc', 'add', 'ade', 'adf', 'adg', 'adh', 'adi', 'adj', 'adk', 'adl', 'adm', 'adn', 'ado', 'adp', 'adq', 'adr', 'ads', 'adt', 'adu', 'adv', 'adw', 'adx', 'ady', 'adz', 'ae', 'aea', 'aeb', 'aec', 'aed', 'aee', 'aef', 'aeg', 'aeh', 'aei', 'aej', 'aek', 'ael', 'aem', 'aen', 'aeo', 'aep', 'aeq', 'aer', 'aes', 'aet', 'aeu', 'aev', 'aew', 'aex', 'aey', 'aez', 'af', 'afa', 'afb', 'afc', 'afd', 'afe', 'aff', 'afg', 'afh', 'afi', 'afj', 'afk', 'afl', 'afm', 'afn', 'afo', 'afp', 'afq', 'afr', 'afs', 'aft', 'afu', 'afv', 'afw', 'afx', 'afy', 'afz', 'ag', 'aga', 'agb', 'agc', 'agd', 'age', 'agf', 'agg', 'agh', 'agi', 'agj', 'agk', 'agl', 'agm', 'agn', 'ago', 'agp', 'agq', 'agr', 'ags', 'agt', 'agu', 'agv', 'agw', 'agx', 'agy', 'agz', 'ah', 'aha', 'ahb', 'ahc', 'ahd', 'ahe', 'ahf', 'ahg', 'ahh', 'ahi', 'ahj', 'ahk', 'ahl', 'ahm', 'ahn', 'aho', 'ahp', 'ahq', 'ahr', 'ahs', 'aht', 'ahu', 'ahv', 'ahw', 'ahx', 'ahy', 'ahz', 'ai', 'aia', 'aib', 'aic', 'aid', 'aie', 'aif', 'aig', 'aih', 'aii', 'aij', 'aik', 'ail', 'aim', 'ain', 'aio', 'aip', 'aiq', 'air', 'ais', 'ait', 'aiu', 'aiv', 'aiw', 'aix', 'aiy', 'aiz', 'aj', 'aja', 'ajb', 'ajc', 'ajd', 'aje', 'ajf', 'ajg', 'ajh', 'aji', 'ajj', 'ajk', 'ajl', 'ajm', 'ajn', 'ajo', 'ajp', 'ajq', 'ajr', 'ajs', 'ajt', 'aju', 'ajv', 'ajw', 'ajx', 'ajy', 'ajz', 'ak', 'aka', 'akb', 'akc', 'akd', 'ake', 'akf', 'akg', 'akh', 'aki', 'akj', 'akk', 'akl', 'akm', 'akn', 'ako', 'akp', 'akq', 'akr', 'aks', 'akt', 'aku', 'akv', 'akw', 'akx', 'aky', 'akz', 'al', 'ala', 'alb', 'alc', 'ald', 'ale', 'alf', 'alg', 'alh', 'ali', 'alj', 'alk', 'all', 'alm', 'aln', 'alo', 'alp', 'alq', 'alr', 'als', 'alt', 'alu', 'alv', 'alw', 'alx', 'aly', 'alz', 'am', 'ama', 'amb', 'amc', 'amd', 'ame', 'amf', 'amg', 'amh', 'ami', 'amj', 'amk', 'aml', 'amm', 'amn', 'amo', 'amp', 'amq', 'amr', 'ams', 'amt', 'amu', 'amv', 'amw', 'amx', 'amy', 'amz', 'an', 'ana', 'anb', 'anc', 'and', 'ane', 'anf', 'ang', 'anh', 'ani', 'anj', 'ank', 'anl', 'anm', 'ann', 'ano', 'anp', 'anq', 'anr', 'ans', 'ant', 'anu', 'anv', 'anw', 'anx', 'any', 'anz', 'ao', 'aoa', 'aob', 'aoc', 'aod', 'aoe', 'aof', 'aog', 'aoh', 'aoi', 'aoj', 'aok', 'aol', 'aom', 'aon', 'aoo', 'aop', 'aoq', 'aor', 'aos', 'aot', 'aou', 'aov', 'aow', 'aox', 'aoy', 'aoz', 'ap', 'apa', 'apb', 'apc', 'apd', 'ape', 'apf', 'apg', 'aph', 'api', 'apj', 'apk', 'apl', 'apm', 'apn', 'apo', 'app', 'apq', 'apr', 'aps', 'apt', 'apu', 'apv', 'apw', 'apx', 'apy', 'apz', 'aq', 'aqa', 'aqb', 'aqc', 'aqd', 'aqe', 'aqf', 'aqg', 'aqh', 'aqi', 'aqj', 'aqk', 'aql', 'aqm', 'aqn', 'aqo', 'aqp', 'aqq', 'aqr', 'aqs', 'aqt', 'aqu', 'aqv', 'aqw', 'aqx', 'aqy', 'aqz', 'ar', 'ara', 'arb', 'arc', 'ard', 'are', 'arf', 'arg', 'arh', 'ari', 'arj', 'ark', 'arl', 'arm', 'arn', 'aro', 'arp', 'arq', 'arr', 'ars', 'art', 'aru', 'arv', 'arw', 'arx', 'ary', 'arz', 'as', 'asa', 'asb', 'asc', 'asd', 'ase', 'asf', 'asg', 'ash', 'asi', 'asj', 'ask', 'asl', 'asm', 'asn', 'aso', 'asp', 'asq', 'asr', 'ass', 'ast', 'asu', 'asv', 'asw', 'asx', 'asy', 'asz', 'at', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aua', 'aub', 'auc', 'aud', 'aue', 'auf', 'aug', 'auh', 'aui', 'auj', 'auk', 'aul', 'aum', 'aun', 'auo', 'aup', 'auq', 'aur', 'aus', 'aut', 'auu', 'auv', 'auw', 'aux', 'auy', 'auz', 'av', 'ava', 'avb', 'avc', 'avd', 'ave', 'avf', 'avg', 'avh', 'avi', 'avj', 'avk', 'avl', 'avm', 'avn', 'avo', 'avp', 'avq', 'avr', 'avs', 'avt', 'avu', 'avv', 'avw', 'avx', 'avy', 'avz', 'aw', 'awa', 'awb', 'awc', 'awd', 'awe', 'awf', 'awg', 'awh', 'awi', 'awj', 'awk', 'awl', 'awm', 'awn', 'awo', 'awp', 'awq', 'awr', 'aws', 'awt', 'awu', 'awv', 'aww', 'awx', 'awy', 'awz', 'ax', 'axa', 'axb', 'axc', 'axd', 'axe', 'axf', 'axg', 'axh', 'axi', 'axj', 'axk', 'axl', 'axm', 'axn', 'axo', 'axp', 'axq', 'axr', 'axs', 'axt', 'axu', 'axv', 'axw', 'axx', 'axy', 'axz', 'ay', 'aya', 'ayb', 'ayc', 'ayd', 'aye', 'ayf', 'ayg', 'ayh', 'ayi', 'ayj', 'ayk', 'ayl', 'aym', 'ayn', 'ayo', 'ayp', 'ayq', 'ayr', 'ays', 'ayt', 'ayu', 'ayv', 'ayw', 'ayx', 'ayy', 'ayz', 'az', 'aza', 'azb', 'azc', 'azd', 'aze', 'azf', 'azg', 'azh', 'azi', 'azj', 'azk', 'azl', 'azm', 'azn', 'azo', 'azp', 'azq', 'azr', 'azs', 'azt', 'azu', 'azv', 'azw', 'azx', 'azy', 'azz', 'b', 'ba', 'baa', 'bab', 'bac', 'bad', 'bae', 'baf', 'bag', 'bah', 'bai', 'baj', 'bak', 'bal', 'bam', 'ban', 'bao', 'bap', 'baq', 'bar', 'bas', 'bat', 'bau', 'bav', 'baw', 'bax', 'bay', 'baz', 'bb', 'bba', 'bc', 'bca', 'bd', 'bda', 'be', 'bea', 'bf', 'bfa', 'bg', 'bga', 'bh', 'bha', 'bi', 'bia', 'bj', 'bja', 'bk', 'bka', 'bl', 'bla', 'bm', 'bma', 'bn', 'bna', 'bo', 'boa', 'bp', 'bpa', 'bq', 'bqa', 'br', 'bra', 'bs', 'bsa', 'bt', 'bta', 'bu', 'bua', 'bv', 'bva', 'bw', 'bwa', 'bx', 'bxa', 'by', 'bya', 'bz', 'bza', 'c', 'ca', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'can', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cb', 'cba', 'cc', 'cca', 'cd', 'cda', 'ce', 'cea', 'cf', 'cfa', 'cg', 'cga', 'ch', 'cha', 'ci', 'cia', 'cj', 'cja', 'ck', 'cka', 'cl', 'cla', 'cm', 'cma', 'cn', 'cna', 'co', 'coa', 'cp', 'cpa', 'cq', 'cqa', 'cr', 'cra', 'cs', 'csa', 'ct', 'cta', 'cu', 'cua', 'cv', 'cva', 'cw', 'cwa', 'cx', 'cxa', 'cy', 'cya', 'cz', 'cza', 'd', 'da', 'daa', 'dab', 'dac', 'dad', 'dae', 'daf', 'dag', 'dah', 'dai', 'daj', 'dak', 'dal', 'dam', 'dan', 'dao', 'dap', 'daq', 'dar', 'das', 'dat', 'dau', 'dav', 'daw', 'dax', 'day', 'daz', 'db', 'dba', 'dc', 'dca', 'dd', 'dda', 'de', 'dea', 'df', 'dfa', 'dg', 'dga', 'dh', 'dha', 'di', 'dia', 'dj', 'dja', 'dk', 'dka', 'dl', 'dla', 'dm', 'dma', 'dn', 'dna', 'do', 'doa', 'dp', 'dpa', 'dq', 'dqa', 'dr', 'dra', 'ds', 'dsa', 'dt', 'dta', 'du', 'dua', 'dv', 'dva', 'dw', 'dwa', 'dx', 'dxa', 'dy', 'dya', 'dz', 'dza', 'e', 'ea', 'eaa', 'eab', 'eac', 'ead', 'eae', 'eaf', 'eag', 'eah', 'eai', 'eaj', 'eak', 'eal', 'eam', 'ean', 'eao', 'eap', 'eaq', 'ear', 'eas', 'eat', 'eau', 'eav', 'eaw', 'eax', 'eay', 'eaz', 'eb', 'eba', 'ec', 'eca', 'ed', 'eda', 'ee', 'eea', 'ef', 'efa', 'eg', 'ega', 'eh', 'eha', 'ei', 'eia', 'ej', 'eja', 'ek', 'eka', 'el', 'ela', 'em', 'ema', 'en', 'ena', 'eo', 'eoa', 'ep', 'epa', 'eq', 'eqa', 'er', 'era', 'es', 'esa', 'et', 'eta', 'eu', 'eua', 'ev', 'eva', 'ew', 'ewa', 'ex', 'exa', 'ey', 'eya', 'ez', 'eza', 'f', 'fa', 'faa', 'fab', 'fac', 'fad', 'fae', 'faf', 'fag', 'fah', 'fai', 'faj', 'fak', 'fal', 'fam', 'fan', 'fao', 'fap', 'faq', 'far', 'fas', 'fat', 'fau', 'fav', 'faw', 'fax', 'fay', 'faz', 'fb', 'fba', 'fc', 'fca', 'fd', 'fda', 'fe', 'fea', 'ff', 'ffa', 'fg', 'fga', 'fh', 'fha', 'fi', 'fia', 'fj', 'fja', 'fk', 'fka', 'fl', 'fla', 'fm', 'fma', 'fn', 'fna', 'fo', 'foa', 'fp', 'fpa', 'fq', 'fqa', 'fr', 'fra', 'fs', 'fsa', 'ft', 'fta', 'fu', 'fua', 'fv', 'fva', 'fw', 'fwa', 'fx', 'fxa', 'fy', 'fya', 'fz', 'fza', 'g', 'ga', 'gaa', 'gab', 'gac', 'gad', 'gae', 'gaf', 'gag', 'gah', 'gai', 'gaj', 'gak', 'gal', 'gam', 'gan', 'gao', 'gap', 'gaq', 'gar', 'gas', 'gat', 'gau', 'gav', 'gaw', 'gax', 'gay', 'gaz', 'gb', 'gba', 'gc', 'gca', 'gd', 'gda', 'ge', 'gea', 'gf', 'gfa', 'gg', 'gga', 'gh', 'gha', 'gi', 'gia', 'gj', 'gja', 'gk', 'gka', 'gl', 'gla', 'gm', 'gma', 'gn', 'gna', 'go', 'goa', 'gp', 'gpa', 'gq', 'gqa', 'gr', 'gra', 'gs', 'gsa', 'gt', 'gta', 'gu', 'gua', 'gv', 'gva', 'gw', 'gwa', 'gx', 'gxa', 'gy', 'gya', 'gz', 'gza', 'h', 'ha', 'haa', 'hab', 'hac', 'had', 'hae', 'haf', 'hag', 'hah', 'hai', 'haj', 'hak', 'hal', 'ham', 'han', 'hao', 'hap', 'haq', 'har', 'has', 'hat', 'hau', 'hav', 'haw', 'hax', 'hay', 'haz', 'hb', 'hba', 'hc', 'hca', 'hd', 'hda', 'he', 'hea', 'hf', 'hfa', 'hg', 'hga', 'hh', 'hha', 'hi', 'hia', 'hj', 'hja', 'hk', 'hka', 'hl', 'hla', 'hm', 'hma', 'hn', 'hna', 'ho', 'hoa', 'hp', 'hpa', 'hq', 'hqa', 'hr', 'hra', 'hs', 'hsa', 'ht', 'hta', 'hu', 'hua', 'hv', 'hva', 'hw', 'hwa', 'hx', 'hxa', 'hy', 'hya', 'hz', 'hza', 'i', 'ia', 'iaa', 'iab', 'iac', 'iad', 'iae', 'iaf', 'iag', 'iah', 'iai', 'iaj', 'iak', 'ial', 'iam', 'ian', 'iao', 'iap', 'iaq', 'iar', 'ias', 'iat', 'iau', 'iav', 'iaw', 'iax', 'iay', 'iaz', 'ib', 'iba', 'ic', 'ica', 'id', 'ida', 'ie', 'iea', 'if', 'ifa', 'ig', 'iga', 'ih', 'iha', 'ii', 'iia', 'ij', 'ija', 'ik', 'ika', 'il', 'ila', 'im', 'ima', 'in', 'ina', 'io', 'ioa', 'ip', 'ipa', 'iq', 'iqa', 'ir', 'ira', 'is', 'isa', 'it', 'ita', 'iu', 'iua', 'iv', 'iva', 'iw', 'iwa', 'ix', 'ixa', 'iy', 'iya', 'iz', 'iza', 'j', 'ja', 'jaa', 'jab', 'jac', 'jad', 'jae', 'jaf', 'jag', 'jah', 'jai', 'jaj', 'jak', 'jal', 'jam', 'jan', 'jao', 'jap', 'jaq', 'jar', 'jas', 'jat', 'jau', 'jav', 'jaw', 'jax', 'jay', 'jaz', 'jb', 'jba', 'jc', 'jca', 'jd', 'jda', 'je', 'jea', 'jf', 'jfa', 'jg', 'jga', 'jh', 'jha', 'ji', 'jia', 'jj', 'jja', 'jk', 'jka', 'jl', 'jla', 'jm', 'jma', 'jn', 'jna', 'jo', 'joa', 'jp', 'jpa', 'jq', 'jqa', 'jr', 'jra', 'js', 'jsa', 'jt', 'jta', 'ju', 'jua', 'jv', 'jva', 'jw', 'jwa', 'jx', 'jxa', 'jy', 'jya', 'jz', 'jza', 'k', 'ka', 'kaa', 'kab', 'kac', 'kad', 'kae', 'kaf', 'kag', 'kah', 'kai', 'kaj', 'kak', 'kal', 'kam', 'kan', 'kao', 'kap', 'kaq', 'kar', 'kas', 'kat', 'kau', 'kav', 'kaw', 'kax', 'kay', 'kaz', 'kb', 'kba', 'kc', 'kca', 'kd', 'kda', 'ke', 'kea', 'kf', 'kfa', 'kg', 'kga', 'kh', 'kha', 'ki', 'kia', 'kj', 'kja', 'kk', 'kka', 'kl', 'kla', 'km', 'kma', 'kn', 'kna', 'ko', 'koa', 'kp', 'kpa', 'kq', 'kqa', 'kr', 'kra', 'ks', 'ksa', 'kt', 'kta', 'ku', 'kua', 'kv', 'kva', 'kw', 'kwa', 'kx', 'kxa', 'ky', 'kya', 'kz', 'kza', 'l', 'la', 'laa', 'lab', 'lac', 'lad', 'lae', 'laf', 'lag', 'lah', 'lai', 'laj', 'lak', 'lal', 'lam', 'lan', 'lao', 'lap', 'laq', 'lar', 'las', 'lat', 'lau', 'lav', 'law', 'lax', 'lay', 'laz', 'lb', 'lba', 'lc', 'lca', 'ld', 'lda', 'le', 'lea', 'lf', 'lfa', 'lg', 'lga', 'lh', 'lha', 'li', 'lia', 'lj', 'lja', 'lk', 'lka', 'll', 'lla', 'lm', 'lma', 'ln', 'lna', 'lo', 'loa', 'lp', 'lpa', 'lq', 'lqa', 'lr', 'lra', 'ls', 'lsa', 'lt', 'lta', 'lu', 'lua', 'lv', 'lva', 'lw', 'lwa', 'lx', 'lxa', 'ly', 'lya', 'lz', 'lza', 'm', 'ma', 'maa', 'mab', 'mac', 'mad', 'mae', 'maf', 'mag', 'mah', 'mai', 'maj', 'mak', 'mal', 'mam', 'man', 'mao', 'map', 'maq', 'mar', 'mas', 'mat', 'mau', 'mav', 'maw', 'max', 'may', 'maz', 'mb', 'mba', 'mc', 'mca', 'md', 'mda', 'me', 'mea', 'mf', 'mfa', 'mg', 'mga', 'mh', 'mha', 'mi', 'mia', 'mj', 'mja', 'mk', 'mka', 'ml', 'mla', 'mm', 'mma', 'mn', 'mna', 'mo', 'moa', 'mp', 'mpa', 'mq', 'mqa', 'mr', 'mra', 'ms', 'msa', 'mt', 'mta', 'mu', 'mua', 'mv', 'mva', 'mw', 'mwa', 'mx', 'mxa', 'my', 'mya', 'mz', 'mza', 'n', 'na', 'naa', 'nab', 'nac', 'nad', 'nae', 'naf', 'nag', 'nah', 'nai', 'naj', 'nak', 'nal', 'nam', 'nan', 'nao', 'nap', 'naq', 'nar', 'nas', 'nat', 'nau', 'nav', 'naw', 'nax', 'nay', 'naz', 'nb', 'nba', 'nc', 'nca', 'nd', 'nda', 'ne', 'nea', 'nf', 'nfa', 'ng', 'nga', 'nh', 'nha', 'ni', 'nia', 'nj', 'nja', 'nk', 'nka', 'nl', 'nla', 'nm', 'nma', 'nn', 'nna', 'no', 'noa', 'np', 'npa', 'nq', 'nqa', 'nr', 'nra', 'ns', 'nsa', 'nt', 'nta', 'nu', 'nua', 'nv', 'nva', 'nw', 'nwa', 'nx', 'nxa', 'ny', 'nya', 'nz', 'nza', 'o', 'oa', 'oaa', 'oab', 'oac', 'oad', 'oae', 'oaf', 'oag', 'oah', 'oai', 'oaj', 'oak', 'oal', 'oam', 'oan', 'oao', 'oap', 'oaq', 'oar', 'oas', 'oat', 'oau', 'oav', 'oaw', 'oax', 'oay', 'oaz', 'ob', 'oba', 'oc', 'oca', 'od', 'oda', 'oe', 'oea', 'of', 'ofa', 'og', 'oga', 'oh', 'oha', 'oi', 'oia', 'oj', 'oja', 'ok', 'oka', 'ol', 'ola', 'om', 'oma', 'on', 'ona', 'oo', 'ooa', 'op', 'opa', 'oq', 'oqa', 'or', 'ora', 'os', 'osa', 'ot', 'ota', 'ou', 'oua', 'ov', 'ova', 'ow', 'owa', 'ox', 'oxa', 'oy', 'oya', 'oz', 'oza', 'p', 'pa', 'paa', 'pab', 'pac', 'pad', 'pae', 'paf', 'pag', 'pah', 'pai', 'paj', 'pak', 'pal', 'pam', 'pan', 'pao', 'pap', 'paq', 'par', 'pas', 'pat', 'pau', 'pav', 'paw', 'pax', 'pay', 'paz', 'pb', 'pba', 'pc', 'pca', 'pd', 'pda', 'pe', 'pea', 'pf', 'pfa', 'pg', 'pga', 'ph', 'pha', 'pi', 'pia', 'pj', 'pja', 'pk', 'pka', 'pl', 'pla', 'pm', 'pma', 'pn', 'pna', 'po', 'poa', 'pp', 'ppa', 'pq', 'pqa', 'pr', 'pra', 'ps', 'psa', 'pt', 'pta', 'pu', 'pua', 'pv', 'pva', 'pw', 'pwa', 'px', 'pxa', 'py', 'pya', 'pz', 'pza', 'q', 'qa', 'qaa', 'qab', 'qac', 'qad', 'qae', 'qaf', 'qag', 'qah', 'qai', 'qaj', 'qak', 'qal', 'qam', 'qan', 'qao', 'qap', 'qaq', 'qar', 'qas', 'qat', 'qau', 'qav', 'qaw', 'qax', 'qay', 'qaz', 'qb', 'qba', 'qc', 'qca', 'qd', 'qda', 'qe', 'qea', 'qf', 'qfa', 'qg', 'qga', 'qh', 'qha', 'qi', 'qia', 'qj', 'qja', 'qk', 'qka', 'ql', 'qla', 'qm', 'qma', 'qn', 'qna', 'qo', 'qoa', 'qp', 'qpa', 'qq', 'qqa', 'qr', 'qra', 'qs', 'qsa', 'qt', 'qta', 'qu', 'qua', 'qv', 'qva', 'qw', 'qwa', 'qx', 'qxa', 'qy', 'qya', 'qz', 'qza', 'r', 'ra', 'raa', 'rab', 'rac', 'rad', 'rae', 'raf', 'rag', 'rah', 'rai', 'raj', 'rak', 'ral', 'ram', 'ran', 'rao', 'rap', 'raq', 'rar', 'ras', 'rat', 'rau', 'rav', 'raw', 'rax', 'ray', 'raz', 'rb', 'rba', 'rc', 'rca', 'rd', 'rda', 're', 'rea', 'rf', 'rfa', 'rg', 'rga', 'rh', 'rha', 'ri', 'ria', 'rj', 'rja', 'rk', 'rka', 'rl', 'rla', 'rm', 'rma', 'rn', 'rna', 'ro', 'roa', 'rp', 'rpa', 'rq', 'rqa', 'rr', 'rra', 'rs', 'rsa', 'rt', 'rta', 'ru', 'rua', 'rv', 'rva', 'rw', 'rwa', 'rx', 'rxa', 'ry', 'rya', 'rz', 'rza', 's', 'sa', 'saa', 'sab', 'sac', 'sad', 'sae', 'saf', 'sag', 'sah', 'sai', 'saj', 'sak', 'sal', 'sam', 'san', 'sao', 'sap', 'saq', 'sar', 'sas', 'sat', 'sau', 'sav', 'saw', 'sax', 'say', 'saz', 'sb', 'sba', 'sc', 'sca', 'sd', 'sda', 'se', 'sea', 'sf', 'sfa', 'sg', 'sga', 'sh', 'sha', 'si', 'sia', 'sj', 'sja', 'sk', 'ska', 'sl', 'sla', 'sm', 'sma', 'sn', 'sna', 'so', 'soa', 'sp', 'spa', 'sq', 'sqa', 'sr', 'sra', 'ss', 'ssa', 'st', 'sta', 'su', 'sua', 'sv', 'sva', 'sw', 'swa', 'sx', 'sxa', 'sy', 'sya', 'sz', 'sza', 't', 'ta', 'taa', 'tab', 'tac', 'tad', 'tae', 'taf', 'tag', 'tah', 'tai', 'taj', 'tak', 'tal', 'tam', 'tan', 'tao', 'tap', 'taq', 'tar', 'tas', 'tat', 'tau', 'tav', 'taw', 'tax', 'tay', 'taz', 'tb', 'tba', 'tc', 'tca', 'td', 'tda', 'te', 'tea', 'tf', 'tfa', 'tg', 'tga', 'th', 'tha', 'ti', 'tia', 'tj', 'tja', 'tk', 'tka', 'tl', 'tla', 'tm', 'tma', 'tn', 'tna', 'to', 'toa', 'tp', 'tpa', 'tq', 'tqa', 'tr', 'tra', 'ts', 'tsa', 'tt', 'tta', 'tu', 'tua', 'tv', 'tva', 'tw', 'twa', 'tx', 'txa', 'ty', 'tya', 'tz', 'tza', 'u', 'ua', 'uaa', 'uab', 'uac', 'uad', 'uae', 'uaf', 'uag', 'uah', 'uai', 'uaj', 'uak', 'ual', 'uam', 'uan', 'uao', 'uap', 'uaq', 'uar', 'uas', 'uat', 'uau', 'uav', 'uaw', 'uax', 'uay', 'uaz', 'ub', 'uba', 'uc', 'uca', 'ud', 'uda', 'ue', 'uea', 'uf', 'ufa', 'ug', 'uga', 'uh', 'uha', 'ui', 'uia', 'uj', 'uja', 'uk', 'uka', 'ul', 'ula', 'um', 'uma', 'un', 'una', 'uo', 'uoa', 'up', 'upa', 'uq', 'uqa', 'ur', 'ura', 'us', 'usa', 'ut', 'uta', 'uu', 'uua', 'uv', 'uva', 'uw', 'uwa', 'ux', 'uxa', 'uy', 'uya', 'uz', 'uza', 'v', 'va', 'vaa', 'vab', 'vac', 'vad', 'vae', 'vaf', 'vag', 'vah', 'vai', 'vaj', 'vak', 'val', 'vam', 'van', 'vao', 'vap', 'vaq', 'var', 'vas', 'vat', 'vau', 'vav', 'vaw', 'vax', 'vay', 'vaz', 'vb', 'vba', 'vc', 'vca', 'vd', 'vda', 've', 'vea', 'vf', 'vfa', 'vg', 'vga', 'vh', 'vha', 'vi', 'via', 'vj', 'vja', 'vk', 'vka', 'vl', 'vla', 'vm', 'vma', 'vn', 'vna', 'vo', 'voa', 'vp', 'vpa', 'vq', 'vqa', 'vr', 'vra', 'vs', 'vsa', 'vt', 'vta', 'vu', 'vua', 'vv', 'vva', 'vw', 'vwa', 'vx', 'vxa', 'vy', 'vya', 'vz', 'vza', 'w', 'wa', 'waa', 'wab', 'wac', 'wad', 'wae', 'waf', 'wag', 'wah', 'wai', 'waj', 'wak', 'wal', 'wam', 'wan', 'wao', 'wap', 'waq', 'war', 'was', 'wat', 'wau', 'wav', 'waw', 'wax', 'way', 'waz', 'wb', 'wba', 'wc', 'wca', 'wd', 'wda', 'we', 'wea', 'wf', 'wfa', 'wg', 'wga', 'wh', 'wha', 'wi', 'wia', 'wj', 'wja', 'wk', 'wka', 'wl', 'wla', 'wm', 'wma', 'wn', 'wna', 'wo', 'woa', 'wp', 'wpa', 'wq', 'wqa', 'wr', 'wra', 'ws', 'wsa', 'wt', 'wta', 'wu', 'wua', 'wv', 'wva', 'ww', 'wwa', 'wx', 'wxa', 'wy', 'wya', 'wz', 'wza', 'x', 'xa', 'xaa', 'xab', 'xac', 'xad', 'xae', 'xaf', 'xag', 'xah', 'xai', 'xaj', 'xak', 'xal', 'xam', 'xan', 'xao', 'xap', 'xaq', 'xar', 'xas', 'xat', 'xau', 'xav', 'xaw', 'xax', 'xay', 'xaz', 'xb', 'xba', 'xc', 'xca', 'xd', 'xda', 'xe', 'xea', 'xf', 'xfa', 'xg', 'xga', 'xh', 'xha', 'xi', 'xia', 'xj', 'xja', 'xk', 'xka', 'xl', 'xla', 'xm', 'xma', 'xn', 'xna', 'xo', 'xoa', 'xp', 'xpa', 'xq', 'xqa', 'xr', 'xra', 'xs', 'xsa', 'xt', 'xta', 'xu', 'xua', 'xv', 'xva', 'xw', 'xwa', 'xx', 'xxa', 'xy', 'xya', 'xz', 'xza', 'y', 'ya', 'yaa', 'yab', 'yac', 'yad', 'yae', 'yaf', 'yag', 'yah', 'yai', 'yaj', 'yak', 'yal', 'yam', 'yan', 'yao', 'yap', 'yaq', 'yar', 'yas', 'yat', 'yau', 'yav', 'yaw', 'yax', 'yay', 'yaz', 'yb', 'yba', 'yc', 'yca', 'yd', 'yda', 'ye', 'yea', 'yf', 'yfa', 'yg', 'yga', 'yh', 'yha', 'yi', 'yia', 'yj', 'yja', 'yk', 'yka', 'yl', 'yla', 'ym', 'yma', 'yn', 'yna', 'yo', 'yoa', 'yp', 'ypa', 'yq', 'yqa', 'yr', 'yra', 'ys', 'ysa', 'yt', 'yta', 'yu', 'yua', 'yv', 'yva', 'yw', 'ywa', 'yx', 'yxa', 'yy', 'yya', 'yz', 'yza', 'z', 'za', 'zaa', 'zab', 'zac', 'zad', 'zae', 'zaf', 'zag', 'zah', 'zai', 'zaj', 'zak', 'zal', 'zam', 'zan', 'zao', 'zap', 'zaq', 'zar', 'zas', 'zat', 'zau', 'zav', 'zaw', 'zax', 'zay', 'zaz', 'zb', 'zba', 'zc', 'zca', 'zd', 'zda', 'ze', 'zea', 'zf', 'zfa', 'zg', 'zga', 'zh', 'zha', 'zi', 'zia', 'zj', 'zja', 'zk', 'zka', 'zl', 'zla', 'zm', 'zma', 'zn', 'zna', 'zo', 'zoa', 'zp', 'zpa', 'zq', 'zqa', 'zr', 'zra', 'zs', 'zsa', 'zt', 'zta', 'zu', 'zua', 'zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggest Spelling Suggestions"
      ],
      "metadata": {
        "id": "tZqX38EoVUw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'suggestion algorithm' follows this logic:\n",
        "\n",
        "- If the word is in the vocabulary, suggest the word.\n",
        "- Otherwise, if there are suggestions from edit_one_letter that are in the vocabulary, use those.\n",
        "- Otherwise, if there are suggestions from edit_two_letters that are in the vocabulary, use those.\n",
        "- Otherwise, suggest the input word.\n",
        "\n",
        "The idea is that words generated from fewer edits are more likely than words with more edits."
      ],
      "metadata": {
        "id": "1HhpOYXGVb8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Then create a 'best_words' dictionary where the 'key' is a suggestion and the 'value' is the probability of that word in your vocabulary.\n",
        "\n",
        "> Select the n best suggestions. There may be fewer than n"
      ],
      "metadata": {
        "id": "5-TGvpWkXOWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Input:\n",
        "        word: a user entered string to check for suggestions\n",
        "        probs: a dictionary that maps each word to its probability in the corpus\n",
        "        vocab: a set containing all the vocabulary\n",
        "        n: number of possible word corrections you want returned in the dictionary\n",
        "    Output:\n",
        "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n"
      ],
      "metadata": {
        "id": "F10i0y5WOt_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "\n",
        "\n",
        "    suggestions = list((word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(vocab))\n",
        "    n_best = [(s, probs[s]) for s in suggestions]\n",
        "\n",
        "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "FyvOdSXZVUTh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the function"
      ],
      "metadata": {
        "id": "TpX815iIO_KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "my_word = 'dys'\n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "JKAntNjcOtmh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}